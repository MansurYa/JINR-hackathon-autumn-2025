"""
–ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥—É–ª—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö —Ç–µ–≥–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM.
–≠–¢–ê–ü 1 –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è).
"""

import json
import os
import re
from typing import Dict, Optional
from openrouter_client import OpenRouterClient
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock


def load_config(config_path: str = "../config.json") -> Dict:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ config.json.

    Args:
        config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    """
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    required_fields = ["api_key", "model_name", "temperature", "max_response_tokens"]
    for field in required_fields:
        if field not in config:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –≤ config.json: {field}")

    return config


def load_prompt(prompt_path: str = "../prompt.txt") -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞.

    Args:
        prompt_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–æ–º

    Returns:
        –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    """
    if not os.path.exists(prompt_path):
        raise FileNotFoundError(f"–§–∞–π–ª —Å –ø—Ä–æ–º–ø—Ç–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}")

    with open(prompt_path, 'r', encoding='utf-8') as f:
        return f.read()


def is_english(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–º (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞).

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    Returns:
        True, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    cyrillic_pattern = re.compile('[–∞-—è–ê-–Ø—ë–Å]')
    return not bool(cyrillic_pattern.search(text))


def parse_tags_and_weights(response: str) -> Optional[Dict[str, float]]:
    """
    –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏ —Å –≤–µ—Å–∞–º–∏.

    –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: "Tag1: 0.6, Tag2: 0.2, Tag3: 0.15, Tag4: 0.05"

    Args:
        response: –û—Ç–≤–µ—Ç –æ—Ç LLM

    Returns:
        –°–ª–æ–≤–∞—Ä—å {—Ç–µ–≥: –≤–µ—Å} –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        response = response.strip()

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π
        tag_weight_pairs = response.split(',')

        tags_dict = {}
        for pair in tag_weight_pairs:
            pair = pair.strip()
            if ':' not in pair:
                continue

            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ç–µ–≥ –∏ –≤–µ—Å
            parts = pair.split(':')
            if len(parts) != 2:
                continue

            tag = parts[0].strip()
            weight_str = parts[1].strip()

            # –ü–∞—Ä—Å–∏–º –≤–µ—Å
            try:
                weight = float(weight_str)
            except ValueError:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –≤–µ—Å: {weight_str}")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–≥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
            if not is_english(tag):
                print(f"‚ö†Ô∏è –¢–µ–≥ –Ω–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º): {tag}")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å
            if weight <= 0.0 or weight > 1.0:
                print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–µ—Å –¥–ª—è —Ç–µ–≥–∞ '{tag}': {weight}")
                continue

            tags_dict[tag] = weight

        if not tags_dict:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–µ–≥–∞")
            return None

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å–∞, —á—Ç–æ–±—ã —Å—É–º–º–∞ –±—ã–ª–∞ 1.0
        total_weight = sum(tags_dict.values())
        if abs(total_weight - 1.0) > 0.01:  # –î–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å
            print(f"‚ö†Ô∏è –°—É–º–º–∞ –≤–µ—Å–æ–≤ –Ω–µ —Ä–∞–≤–Ω–∞ 1.0 ({total_weight}), –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º...")
            tags_dict = {tag: weight / total_weight for tag, weight in tags_dict.items()}

        return tags_dict

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
        print(f"–û—Ç–≤–µ—Ç: {response}")
        return None


def process_single_document(document: Dict, system_prompt: str, client: OpenRouterClient, line_num: int) -> Optional[Dict]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–æ—Ç–æ–∫–µ).

    Args:
        document: –î–æ–∫—É–º–µ–Ω—Ç –∏–∑ JSONL
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        client: –ö–ª–∏–µ–Ω—Ç OpenRouter API
        line_num: –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–∞–π–ª–µ

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π
        if 'id' not in document:
            print(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num} –Ω–µ –∏–º–µ–µ—Ç ID, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return None

        doc_id = document['id']
        doc_name = document.get('name', 'Unknown')
        doc_text = document.get('text_of_document', '')

        if not doc_text:
            print(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç ID={doc_id} –Ω–µ –∏–º–µ–µ—Ç —Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return None

        print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ID={doc_id}: '{doc_name[:50]}...'")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
        user_message = f"Document title: {doc_name}\n\nDocument text:\n{doc_text}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
        try:
            response = client.call_api(system_prompt, user_message)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ ID={doc_id}: {e}")
            return None

        # –ü–∞—Ä—Å–∏–º —Ç–µ–≥–∏ –∏ –≤–µ—Å–∞
        tags_dict = parse_tags_and_weights(response)

        if tags_dict is None or len(tags_dict) == 0:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–≥–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ ID={doc_id}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return None

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "document_id": doc_id,
            "tags": tags_dict
        }

        print(f"‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(tags_dict)} —Ç–µ–≥–æ–≤ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ ID={doc_id}")
        print(f"  –¢–µ–≥–∏: {', '.join([f'{tag}: {weight:.2f}' for tag, weight in list(tags_dict.items())[:3]])}...")

        return result

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num}: {e}")
        return None


def extract_tags_from_documents(
    input_file: str,
    output_file: str,
    config_path: str = "../config.json",
    prompt_path: str = "../prompt.txt",
    num_threads: int = 32
) -> int:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ JSONL —Ñ–∞–π–ª–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª (–º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –≤–µ—Ä—Å–∏—è).

    Args:
        input_file: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É JSONL —Ñ–∞–π–ª—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSONL —Ñ–∞–π–ª—É —Å —Ç–µ–≥–∞–º–∏
        config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        prompt_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        num_threads: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –ø—Ä–æ–º–ø—Ç
    config = load_config(config_path)
    system_prompt = load_prompt(prompt_path)

    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
    if "num_threads" in config:
        num_threads = config["num_threads"]

    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
    client = OpenRouterClient(
        api_key=config["api_key"],
        model_name=config["model_name"],
        max_response_tokens=config["max_response_tokens"],
        temperature=config["temperature"]
    )

    print("="*60)
    print("–≠–¢–ê–ü 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM (FAST)")
    print("="*60)
    print(f"–ú–æ–¥–µ–ª—å: {config['model_name']}")
    print(f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {config['temperature']}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤: {num_threads}")
    print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
    print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")
    print("="*60)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞
    documents = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                document = json.loads(line)
                documents.append((document, line_num))
            except json.JSONDecodeError as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num}: {e}")

    total_documents = len(documents)
    print(f"\nüìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_documents}")

    # –°—á–µ—Ç—á–∏–∫–∏
    processed_documents = 0
    skipped_documents = 0
    write_lock = Lock()

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
    with open(output_file, 'w', encoding='utf-8') as f_out:
        # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏ –≤ –ø—É–ª –ø–æ—Ç–æ–∫–æ–≤
            futures = {
                executor.submit(process_single_document, doc, system_prompt, client, line_num): (doc, line_num)
                for doc, line_num in documents
            }

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            for future in as_completed(futures):
                result = future.result()

                if result is not None:
                    # –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
                    with write_lock:
                        f_out.write(json.dumps(result, ensure_ascii=False) + '\n')
                        f_out.flush()
                    processed_documents += 1
                else:
                    skipped_documents += 1

    print("\n" + "="*60)
    print("–≠–¢–ê–ü 1 –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print("="*60)
    print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_documents}")
    print(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_documents}")
    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_documents}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    print("="*60)

    return processed_documents


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
    input_file = "../temporary_data/fake_data.jsonl"
    output_file = "../temporary_data/fake_data_tags.jsonl"

    try:
        count = extract_tags_from_documents(input_file, output_file)
        print(f"\n‚úì –≠–¢–ê–ü 1 –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {count}")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
